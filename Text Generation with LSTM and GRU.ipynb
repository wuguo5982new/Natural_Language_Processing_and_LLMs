{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eMzwwRnv3p3N"
   },
   "source": [
    "# Text generation with LSTM / GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset: text from Shakespeare.\n",
    "\n",
    "To explore Recurrent Neural Networks. Model will convert each character to its embedding, run the embeddings through LSTM or GRU, predict the next set of characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 2767,
     "status": "ok",
     "timestamp": 1593683688129,
     "user": {
      "displayName": "Vijay Gadhave",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh8AeAj-bn6r8wj43bKiCJEywC8wSd5igowbxpPuQ=s64",
      "userId": "02099433176152859365"
     },
     "user_tz": -330
    },
    "id": "hhV8hhIGkfoW",
    "outputId": "7c186cf9-fbca-47b4-bc99-9b1974a0730c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "for device in gpu_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)\n",
    "print(tf.__version__)\n",
    "\n",
    "import string     \n",
    "import requests   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GWjxzbCL3tG9"
   },
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "id": "YHPDViNdmK3v"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124456\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dirname = './'\n",
    "filename = 'shakespeare.txt'\n",
    "lines = [] # storing all the lines in a variable. \n",
    "# for filename in os.listdir(dirname):\n",
    "with open(os.path.join(dirname, filename)) as files:\n",
    "    for line in files:\n",
    "        # remove leading and trailing whitespace\n",
    "        pure_line = line.strip('\\n')\n",
    "        \n",
    "        # if pure_line is not the empty string,\n",
    "#         if pure_line:\n",
    "            # append it to the list\n",
    "        lines.append(pure_line)\n",
    "print(len(lines))\n",
    "# Start the data fron index 253, since data[:253] is not work of shakespeare\n",
    "# Print the first line of shakespeare creation\n",
    "data = lines[253:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "id": "GMs57Oh14ZrN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['from', 'fairest', 'creatures', 'we', 'desire', 'increase', 'that', 'thereby', 'beautys', 'rose', 'might', 'never', 'die', 'but', 'as', 'the', 'riper', 'should', 'by', 'time', 'decease', 'his', 'tender', 'heir', 'might', 'bear', 'his', 'memory', 'but', 'thou', 'contracted', 'to', 'thine', 'own', 'bright', 'eyes', 'feedst', 'thy', 'lights', 'flame', 'with', 'selfsubstantial', 'fuel', 'making', 'a', 'famine', 'where', 'abundance', 'lies', 'thy']\n"
     ]
    }
   ],
   "source": [
    "# Text cleaning\n",
    "data = \" \".join(data)\n",
    "def clean_text(doc):\n",
    "  tokens = doc.split()\n",
    "  table = str.maketrans('','', string.punctuation)        # remove the punctuations\n",
    "  tokens = [(w.translate(table)) for w in tokens]  # list without punctuations (removing the punctuations)\n",
    "  tokens = [word for word in tokens if word.isalpha()]   # remove non alphanumeric special charactors\n",
    "  tokens = [word.lower() for word in tokens]               # convert into lowercase letters\n",
    "  return tokens\n",
    "\n",
    "# we will use these 50 tokens as seed text\n",
    "tokens = clean_text(data)\n",
    "print(tokens[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 4015,
     "status": "ok",
     "timestamp": 1593683731130,
     "user": {
      "displayName": "Vijay Gadhave",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh8AeAj-bn6r8wj43bKiCJEywC8wSd5igowbxpPuQ=s64",
      "userId": "02099433176152859365"
     },
     "user_tz": -330
    },
    "id": "i0WLSRXZCYb1",
    "outputId": "716bb02c-ab4c-4306-802d-763879c1ce3c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "898199 27956\n"
     ]
    }
   ],
   "source": [
    "# Numbers of tokens and number of unique words\n",
    "print(len(tokens), len(set(tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "iEWSmrQeCYmW"
   },
   "outputs": [],
   "source": [
    "# Use 50 set of words to predict the next word (51th)\n",
    "length = 50+1  # 50 is for input and 50+1 is for output\n",
    "lines = []\n",
    "for i in range(length, len(tokens)):   # this range will start from length(51)\n",
    "  seq = tokens[i-length:i]             # seq = 0 to 51 for first sequence\n",
    "  line = ' '.join(seq)                 # join tokens to create a line\n",
    "  lines.append(line)                   # a single line is sequence of 51 words, append that line in list (lines)\n",
    "  if i > 200000:                       # take first 200k words to train the model, it will reduce the time and required resourses  \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 1226,
     "status": "ok",
     "timestamp": 1593683736922,
     "user": {
      "displayName": "Vijay Gadhave",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh8AeAj-bn6r8wj43bKiCJEywC8wSd5igowbxpPuQ=s64",
      "userId": "02099433176152859365"
     },
     "user_tz": -330
    },
    "id": "7RvC9avK0LU7",
    "outputId": "337a977a-0acf-4aa2-cf11-7a7f33f3cf7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199951\n",
      "from fairest creatures we desire increase that thereby beautys rose might never die but as the riper should by time decease his tender heir might bear his memory but thou contracted to thine own bright eyes feedst thy lights flame with selfsubstantial fuel making a famine where abundance lies thy self\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('from', 'self')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# totel number of sequences\n",
    "print(len(lines))\n",
    "print(lines[0])               # at index 0 you can see first 51 words\n",
    "tokens[0], tokens[50]  # first word amd 51th word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pn9fmSkI1h8O"
   },
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "09wvpdTM1tFs"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras .utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Embedding, GRU, Dropout\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "id": "4wGyGBlQoPQU"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  47, 1408, 1264, ...,  466,   31,  307],\n",
       "       [1408, 1264,   37, ...,   31,  307,   31],\n",
       "       [1264,   37,  451, ...,  307,   31, 1582],\n",
       "       ...,\n",
       "       [  33,   80, 5197, ...,  215,   44,   30],\n",
       "       [  80, 5197,  103, ...,   44,   30, 1332],\n",
       "       [5197,  103, 1846, ...,   30, 1332,    2]])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenization\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(lines) # fit lines in tokenization\n",
    "sequences = tokenizer.texts_to_sequences(lines)        # word embedding\n",
    "# Convert sequences array into numpy array\n",
    "sequences = np.array(sequences)\n",
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "id": "GY9dqhYBs11X"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   47  1408  1264    37   451  1406     9  2766  1158  1213   171   132\n",
      "   269    20    24     1  4782    87    30    98  4781    18   715  1263\n",
      "   171   211    18   829    20    27  3807     4   214   121  1212   153\n",
      " 13004    31  2765  1847    16 13003 13002   754     7  3806    99  2430\n",
      "   466    31]\n",
      "[ 307   31 1582 ...   30 1332    2]\n"
     ]
    }
   ],
   "source": [
    "# create x and y\n",
    "# rows = line of play, columns = first 50 columns is x and 51st column is y\n",
    "x, y = sequences[:, :-1], sequences[:, -1]\n",
    "print(x[0])\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 7278,
     "status": "ok",
     "timestamp": 1593683767315,
     "user": {
      "displayName": "Vijay Gadhave",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh8AeAj-bn6r8wj43bKiCJEywC8wSd5igowbxpPuQ=s64",
      "userId": "02099433176152859365"
     },
     "user_tz": -330
    },
    "id": "m-hpmV71zVZz",
    "outputId": "9c5e76cd-510d-49b5-f3bf-0e82cae8096d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13009 27956\n",
      "50\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# length of total vocabulary\n",
    "vocab_size = len(tokenizer.word_index) + 1 \n",
    "print(vocab_size, len(set(tokens)))\n",
    "y = to_categorical(y, num_classes=vocab_size)\n",
    "seq_length = x.shape[1]\n",
    "print(seq_length)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "umBDyxFr18K7"
   },
   "source": [
    "## Build the LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "id": "tO_IUyfe19jv"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# First embedding layer\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=50, input_length=seq_length))\n",
    "# First LSTM layer\n",
    "model.add(LSTM(units=100, return_sequences=True))\n",
    "# Second LSTM layer\n",
    "model.add(LSTM(units=100))\n",
    "# Dense layer\n",
    "model.add(Dense(units=100,activation='relu'))\n",
    "# Final layer\n",
    "model.add(Dense(units=vocab_size, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 329
    },
    "executionInfo": {
     "elapsed": 8382,
     "status": "ok",
     "timestamp": 1593683780795,
     "user": {
      "displayName": "Vijay Gadhave",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh8AeAj-bn6r8wj43bKiCJEywC8wSd5igowbxpPuQ=s64",
      "userId": "02099433176152859365"
     },
     "user_tz": -330
    },
    "id": "xPrRlbJB3c8A",
    "outputId": "56ad5444-79f0-433d-b93e-79221cf702b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_19 (Embedding)     (None, 50, 50)            650450    \n",
      "_________________________________________________________________\n",
      "lstm_15 (LSTM)               (None, 50, 100)           60400     \n",
      "_________________________________________________________________\n",
      "lstm_16 (LSTM)               (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 13009)             1313909   \n",
      "=================================================================\n",
      "Total params: 2,115,259\n",
      "Trainable params: 2,115,259\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# summary of model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 4735250,
     "status": "ok",
     "timestamp": 1593688600042,
     "user": {
      "displayName": "Vijay Gadhave",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh8AeAj-bn6r8wj43bKiCJEywC8wSd5igowbxpPuQ=s64",
      "userId": "02099433176152859365"
     },
     "user_tz": -330
    },
    "id": "p1C_SacQ5Axu",
    "outputId": "1455f2f2-e75c-400f-a032-79736354f529"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "782/782 [==============================] - 24s 30ms/step - loss: 6.8780 - accuracy: 0.0307\n",
      "Epoch 2/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 6.5162 - accuracy: 0.0445\n",
      "Epoch 3/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 6.2987 - accuracy: 0.0607\n",
      "Epoch 4/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 6.1165 - accuracy: 0.0753\n",
      "Epoch 5/100\n",
      "782/782 [==============================] - 23s 29ms/step - loss: 5.9793 - accuracy: 0.0874\n",
      "Epoch 6/100\n",
      "782/782 [==============================] - 22s 29ms/step - loss: 5.8672 - accuracy: 0.0950\n",
      "Epoch 7/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 5.7725 - accuracy: 0.0996\n",
      "Epoch 8/100\n",
      "782/782 [==============================] - ETA: 0s - loss: 5.7051 - accuracy: 0.10 - 22s 28ms/step - loss: 5.7052 - accuracy: 0.1010\n",
      "Epoch 9/100\n",
      "782/782 [==============================] - 22s 29ms/step - loss: 5.6119 - accuracy: 0.1056\n",
      "Epoch 10/100\n",
      "782/782 [==============================] - 23s 29ms/step - loss: 5.5166 - accuracy: 0.1086\n",
      "Epoch 11/100\n",
      "782/782 [==============================] - 23s 29ms/step - loss: 5.4255 - accuracy: 0.1115\n",
      "Epoch 12/100\n",
      "782/782 [==============================] - 22s 29ms/step - loss: 5.3453 - accuracy: 0.1142\n",
      "Epoch 13/100\n",
      "782/782 [==============================] - 23s 29ms/step - loss: 5.2619 - accuracy: 0.1159\n",
      "Epoch 14/100\n",
      "782/782 [==============================] - 23s 29ms/step - loss: 5.1817 - accuracy: 0.1178\n",
      "Epoch 15/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 5.0993 - accuracy: 0.1202\n",
      "Epoch 16/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 5.0260 - accuracy: 0.1225\n",
      "Epoch 17/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 4.9630 - accuracy: 0.1248\n",
      "Epoch 18/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 4.8851 - accuracy: 0.1294\n",
      "Epoch 19/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 4.8144 - accuracy: 0.1342\n",
      "Epoch 20/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 4.7475 - accuracy: 0.1397\n",
      "Epoch 21/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 4.6857 - accuracy: 0.1447\n",
      "Epoch 22/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 4.6268 - accuracy: 0.1495\n",
      "Epoch 23/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 4.5719 - accuracy: 0.1550\n",
      "Epoch 24/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 4.5210 - accuracy: 0.1606\n",
      "Epoch 25/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 4.4748 - accuracy: 0.1649\n",
      "Epoch 26/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 4.4295 - accuracy: 0.1695\n",
      "Epoch 27/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 4.3857 - accuracy: 0.1749\n",
      "Epoch 28/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 4.3461 - accuracy: 0.1785\n",
      "Epoch 29/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 4.3074 - accuracy: 0.1831\n",
      "Epoch 30/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 4.2715 - accuracy: 0.1868\n",
      "Epoch 31/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 4.2347 - accuracy: 0.1919\n",
      "Epoch 32/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 4.1990 - accuracy: 0.1963\n",
      "Epoch 33/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 4.1672 - accuracy: 0.1999\n",
      "Epoch 34/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 4.1335 - accuracy: 0.2037\n",
      "Epoch 35/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 4.1023 - accuracy: 0.2066\n",
      "Epoch 36/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 4.0706 - accuracy: 0.2107\n",
      "Epoch 37/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 4.0417 - accuracy: 0.2140\n",
      "Epoch 38/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 4.0103 - accuracy: 0.2189\n",
      "Epoch 39/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 3.9822 - accuracy: 0.2221\n",
      "Epoch 40/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 3.9537 - accuracy: 0.2258\n",
      "Epoch 41/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 3.9244 - accuracy: 0.2298\n",
      "Epoch 42/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 3.8979 - accuracy: 0.2327\n",
      "Epoch 43/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 3.8685 - accuracy: 0.2365\n",
      "Epoch 44/100\n",
      "782/782 [==============================] - 22s 29ms/step - loss: 3.8440 - accuracy: 0.2397\n",
      "Epoch 45/100\n",
      "782/782 [==============================] - 23s 29ms/step - loss: 3.8180 - accuracy: 0.2427\n",
      "Epoch 46/100\n",
      "782/782 [==============================] - 23s 29ms/step - loss: 3.7927 - accuracy: 0.2465\n",
      "Epoch 47/100\n",
      "782/782 [==============================] - 22s 29ms/step - loss: 3.7686 - accuracy: 0.2493\n",
      "Epoch 48/100\n",
      "782/782 [==============================] - 22s 29ms/step - loss: 3.7427 - accuracy: 0.2530\n",
      "Epoch 49/100\n",
      "782/782 [==============================] - 23s 29ms/step - loss: 3.7189 - accuracy: 0.2563\n",
      "Epoch 50/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 3.6961 - accuracy: 0.2593\n",
      "Epoch 51/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 3.6714 - accuracy: 0.2635\n",
      "Epoch 52/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 3.6477 - accuracy: 0.2654\n",
      "Epoch 53/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 3.6248 - accuracy: 0.2688\n",
      "Epoch 54/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 3.6052 - accuracy: 0.2722\n",
      "Epoch 55/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 3.5819 - accuracy: 0.2749\n",
      "Epoch 56/100\n",
      "782/782 [==============================] - 22s 29ms/step - loss: 3.5620 - accuracy: 0.2777\n",
      "Epoch 57/100\n",
      "782/782 [==============================] - 22s 29ms/step - loss: 3.5382 - accuracy: 0.2813\n",
      "Epoch 58/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 3.5402 - accuracy: 0.2828\n",
      "Epoch 59/100\n",
      "782/782 [==============================] - 22s 29ms/step - loss: 3.7401 - accuracy: 0.2534\n",
      "Epoch 60/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 3.5740 - accuracy: 0.2786\n",
      "Epoch 61/100\n",
      "782/782 [==============================] - 22s 29ms/step - loss: 3.5354 - accuracy: 0.2840\n",
      "Epoch 62/100\n",
      "782/782 [==============================] - 22s 29ms/step - loss: 3.5025 - accuracy: 0.2889\n",
      "Epoch 63/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 3.4791 - accuracy: 0.2920\n",
      "Epoch 64/100\n",
      "782/782 [==============================] - 22s 29ms/step - loss: 3.4495 - accuracy: 0.2965\n",
      "Epoch 65/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 3.4217 - accuracy: 0.2998\n",
      "Epoch 66/100\n",
      "782/782 [==============================] - 22s 29ms/step - loss: 3.3963 - accuracy: 0.3030\n",
      "Epoch 67/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 3.3794 - accuracy: 0.3057\n",
      "Epoch 68/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 3.4032 - accuracy: 0.2998\n",
      "Epoch 69/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 3.3628 - accuracy: 0.3071\n",
      "Epoch 70/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 3.3335 - accuracy: 0.3120\n",
      "Epoch 71/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 3.3169 - accuracy: 0.3140\n",
      "Epoch 72/100\n",
      "782/782 [==============================] - 23s 29ms/step - loss: 3.3014 - accuracy: 0.3165\n",
      "Epoch 73/100\n",
      "782/782 [==============================] - 22s 29ms/step - loss: 3.2841 - accuracy: 0.3199\n",
      "Epoch 74/100\n",
      "782/782 [==============================] - 22s 29ms/step - loss: 3.2662 - accuracy: 0.3211\n",
      "Epoch 75/100\n",
      "782/782 [==============================] - 22s 29ms/step - loss: 3.2510 - accuracy: 0.3242\n",
      "Epoch 76/100\n",
      "782/782 [==============================] - 22s 29ms/step - loss: 3.2349 - accuracy: 0.3268\n",
      "Epoch 77/100\n",
      "782/782 [==============================] - ETA: 0s - loss: 3.2224 - accuracy: 0.32 - 22s 29ms/step - loss: 3.2224 - accuracy: 0.3286\n",
      "Epoch 78/100\n",
      "782/782 [==============================] - 23s 29ms/step - loss: 3.2083 - accuracy: 0.3310\n",
      "Epoch 79/100\n",
      "782/782 [==============================] - 23s 29ms/step - loss: 3.1957 - accuracy: 0.3329\n",
      "Epoch 80/100\n",
      "782/782 [==============================] - 22s 29ms/step - loss: 3.1839 - accuracy: 0.3343\n",
      "Epoch 81/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 3.1691 - accuracy: 0.3365\n",
      "Epoch 82/100\n",
      "782/782 [==============================] - 22s 29ms/step - loss: 3.1562 - accuracy: 0.3383\n",
      "Epoch 83/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 3.1434 - accuracy: 0.3409\n",
      "Epoch 84/100\n",
      "782/782 [==============================] - 23s 29ms/step - loss: 3.1347 - accuracy: 0.3421\n",
      "Epoch 85/100\n",
      "782/782 [==============================] - 23s 29ms/step - loss: 3.1204 - accuracy: 0.3442\n",
      "Epoch 86/100\n",
      "782/782 [==============================] - 22s 29ms/step - loss: 3.1069 - accuracy: 0.3470\n",
      "Epoch 87/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 3.0917 - accuracy: 0.3483\n",
      "Epoch 88/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 3.0882 - accuracy: 0.3495\n",
      "Epoch 89/100\n",
      "782/782 [==============================] - 22s 29ms/step - loss: 3.0668 - accuracy: 0.3525\n",
      "Epoch 90/100\n",
      "782/782 [==============================] - 22s 29ms/step - loss: 3.0532 - accuracy: 0.3549\n",
      "Epoch 91/100\n",
      "782/782 [==============================] - 22s 29ms/step - loss: 3.0405 - accuracy: 0.3569\n",
      "Epoch 92/100\n",
      "782/782 [==============================] - 22s 29ms/step - loss: 3.0282 - accuracy: 0.3576\n",
      "Epoch 93/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 3.0138 - accuracy: 0.3603\n",
      "Epoch 94/100\n",
      "782/782 [==============================] - 23s 29ms/step - loss: 3.0031 - accuracy: 0.3622\n",
      "Epoch 95/100\n",
      "782/782 [==============================] - 23s 29ms/step - loss: 2.9898 - accuracy: 0.3640\n",
      "Epoch 96/100\n",
      "782/782 [==============================] - ETA: 0s - loss: 2.9758 - accuracy: 0.36 - 23s 29ms/step - loss: 2.9759 - accuracy: 0.3671\n",
      "Epoch 97/100\n",
      "782/782 [==============================] - 23s 29ms/step - loss: 2.9631 - accuracy: 0.3688\n",
      "Epoch 98/100\n",
      "782/782 [==============================] - 23s 29ms/step - loss: 2.9532 - accuracy: 0.3711\n",
      "Epoch 99/100\n",
      "782/782 [==============================] - 23s 29ms/step - loss: 2.9336 - accuracy: 0.3729\n",
      "Epoch 100/100\n",
      "782/782 [==============================] - 23s 29ms/step - loss: 2.9234 - accuracy: 0.3755\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e44df21e20>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "# Train the model\n",
    "model.fit(x,y, batch_size=256,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "executionInfo": {
     "elapsed": 1479,
     "status": "ok",
     "timestamp": 1589387536695,
     "user": {
      "displayName": "Vijay Gadhave",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh8AeAj-bn6r8wj43bKiCJEywC8wSd5igowbxpPuQ=s64",
      "userId": "02099433176152859365"
     },
     "user_tz": -330
    },
    "id": "A5Eznsu6CJw6",
    "outputId": "1a128421-8fc8-4408-943f-5effc923c73e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "home of love if i have ranged like him that travels i return again just to the time not with the time exchanged so that my self bring water for my stain never believe though in my nature reigned all frailties that besiege all kinds of blood that it could so\n"
     ]
    }
   ],
   "source": [
    "print(lines[12343])\n",
    "seed_text = lines[12343]\n",
    "# put this line as seed text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "id": "oXsa7SDbCKVJ"
   },
   "outputs": [],
   "source": [
    "# ML model will predict the word on the basis of what it learned\n",
    "# define a function\n",
    "def generate_text_seq(model, tokenizer, text_seq_length, seed_text, n_words):\n",
    "  text = []\n",
    "  for _ in range(n_words):\n",
    "    encoded = tokenizer.texts_to_sequences([seed_text])[0]  # 0 is for zeroth dimention of array\n",
    "    encoded = pad_sequences([encoded], maxlen = text_seq_length, truncating='pre')\n",
    "    y_predict = model.predict_classes(encoded)\n",
    "    \n",
    "    predicted_word = ''\n",
    "    for word, index in tokenizer.word_index.items():    # for each of these words we are checking, it matches with y_pred or not\n",
    "      if index == y_predict:\n",
    "        predicted_word = word\n",
    "        break\n",
    "    seed_text = seed_text + ' ' + predicted_word\n",
    "    text.append(predicted_word)\n",
    "  return ' '.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 1713,
     "status": "ok",
     "timestamp": 1589387544581,
     "user": {
      "displayName": "Vijay Gadhave",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh8AeAj-bn6r8wj43bKiCJEywC8wSd5igowbxpPuQ=s64",
      "userId": "02099433176152859365"
     },
     "user_tz": -330
    },
    "id": "tz82vpZWyna4",
    "outputId": "146e971e-84cb-4c62-cc88-5979365dae92"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'preposterously be stained to leave to make me leave to'"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text_seq(model, tokenizer, seq_length, seed_text, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the GRU Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_12 (Embedding)     (None, 50, 50)            650450    \n",
      "_________________________________________________________________\n",
      "gru_18 (GRU)                 (None, 50, 100)           45600     \n",
      "_________________________________________________________________\n",
      "gru_19 (GRU)                 (None, 100)               60600     \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 200)               20200     \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 13009)             2614809   \n",
      "=================================================================\n",
      "Total params: 3,391,659\n",
      "Trainable params: 3,391,659\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2 = Sequential()\n",
    "# First embedding layer\n",
    "model_2.add(Embedding(input_dim=vocab_size, output_dim=50, input_length=seq_length))\n",
    "# First GRU layer\n",
    "model_2.add(GRU(units=100, return_sequences=True))\n",
    "# model_2.add(Dropout(0.5))\n",
    "# Second GRU layer\n",
    "model_2.add(GRU(units=100))\n",
    "model_2.add(Dropout(0.2))\n",
    "# Dense layer\n",
    "model_2.add(Dense(units=200, activation='relu'))\n",
    "# model_2.add(Dropout(0.5))\n",
    "# Final layer\n",
    "model_2.add(Dense(units=vocab_size, activation='softmax'))\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 6.8576 - accuracy: 0.0324\n",
      "Epoch 2/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 6.3880 - accuracy: 0.0587\n",
      "Epoch 3/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 6.0432 - accuracy: 0.0879\n",
      "Epoch 4/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 5.8103 - accuracy: 0.1004\n",
      "Epoch 5/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 5.6220 - accuracy: 0.1091\n",
      "Epoch 6/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 5.4531 - accuracy: 0.1154\n",
      "Epoch 7/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 5.2967 - accuracy: 0.1221\n",
      "Epoch 8/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 5.1442 - accuracy: 0.1286\n",
      "Epoch 9/100\n",
      "782/782 [==============================] - 22s 29ms/step - loss: 4.9948 - accuracy: 0.1345\n",
      "Epoch 10/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 4.8533 - accuracy: 0.1414\n",
      "Epoch 11/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 4.7121 - accuracy: 0.1479\n",
      "Epoch 12/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 4.5776 - accuracy: 0.1555\n",
      "Epoch 13/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 4.4449 - accuracy: 0.1654\n",
      "Epoch 14/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 4.3237 - accuracy: 0.1758\n",
      "Epoch 15/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 4.2043 - accuracy: 0.1891\n",
      "Epoch 16/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 4.0974 - accuracy: 0.2010\n",
      "Epoch 17/100\n",
      "782/782 [==============================] - 23s 29ms/step - loss: 3.9954 - accuracy: 0.2136\n",
      "Epoch 18/100\n",
      "782/782 [==============================] - 22s 29ms/step - loss: 3.9071 - accuracy: 0.2246\n",
      "Epoch 19/100\n",
      "782/782 [==============================] - 22s 29ms/step - loss: 3.8195 - accuracy: 0.2355\n",
      "Epoch 20/100\n",
      "782/782 [==============================] - 23s 29ms/step - loss: 3.7431 - accuracy: 0.2438\n",
      "Epoch 21/100\n",
      "782/782 [==============================] - 22s 29ms/step - loss: 3.6680 - accuracy: 0.2545\n",
      "Epoch 22/100\n",
      "782/782 [==============================] - 22s 29ms/step - loss: 3.6006 - accuracy: 0.2622\n",
      "Epoch 23/100\n",
      "782/782 [==============================] - 22s 29ms/step - loss: 3.5359 - accuracy: 0.2715\n",
      "Epoch 24/100\n",
      "782/782 [==============================] - 22s 29ms/step - loss: 3.4751 - accuracy: 0.2803\n",
      "Epoch 25/100\n",
      "782/782 [==============================] - 23s 29ms/step - loss: 3.4170 - accuracy: 0.2885\n",
      "Epoch 26/100\n",
      "782/782 [==============================] - 22s 29ms/step - loss: 3.3663 - accuracy: 0.2937\n",
      "Epoch 27/100\n",
      "782/782 [==============================] - 22s 29ms/step - loss: 3.3142 - accuracy: 0.3026\n",
      "Epoch 28/100\n",
      "782/782 [==============================] - 23s 29ms/step - loss: 3.2621 - accuracy: 0.3098\n",
      "Epoch 29/100\n",
      "782/782 [==============================] - 23s 29ms/step - loss: 3.2181 - accuracy: 0.3157\n",
      "Epoch 30/100\n",
      "782/782 [==============================] - 23s 29ms/step - loss: 3.1705 - accuracy: 0.3231\n",
      "Epoch 31/100\n",
      "782/782 [==============================] - 23s 29ms/step - loss: 3.1319 - accuracy: 0.3280\n",
      "Epoch 32/100\n",
      "782/782 [==============================] - 23s 29ms/step - loss: 3.0910 - accuracy: 0.3358\n",
      "Epoch 33/100\n",
      "782/782 [==============================] - 22s 29ms/step - loss: 3.0487 - accuracy: 0.3416\n",
      "Epoch 34/100\n",
      "782/782 [==============================] - 23s 29ms/step - loss: 3.0109 - accuracy: 0.3463\n",
      "Epoch 35/100\n",
      "782/782 [==============================] - 23s 29ms/step - loss: 2.9735 - accuracy: 0.3530\n",
      "Epoch 36/100\n",
      "782/782 [==============================] - 22s 29ms/step - loss: 2.9452 - accuracy: 0.3581\n",
      "Epoch 37/100\n",
      "782/782 [==============================] - 22s 29ms/step - loss: 2.9066 - accuracy: 0.3633\n",
      "Epoch 38/100\n",
      "782/782 [==============================] - 23s 29ms/step - loss: 2.8738 - accuracy: 0.3688\n",
      "Epoch 39/100\n",
      "782/782 [==============================] - 22s 29ms/step - loss: 2.8475 - accuracy: 0.3716\n",
      "Epoch 40/100\n",
      "782/782 [==============================] - 22s 29ms/step - loss: 2.8146 - accuracy: 0.3779\n",
      "Epoch 41/100\n",
      "782/782 [==============================] - 22s 29ms/step - loss: 2.7852 - accuracy: 0.3823\n",
      "Epoch 42/100\n",
      "782/782 [==============================] - 22s 29ms/step - loss: 2.7557 - accuracy: 0.3873\n",
      "Epoch 43/100\n",
      "782/782 [==============================] - 22s 29ms/step - loss: 2.7293 - accuracy: 0.3908\n",
      "Epoch 44/100\n",
      "782/782 [==============================] - 22s 29ms/step - loss: 2.7013 - accuracy: 0.3967\n",
      "Epoch 45/100\n",
      "782/782 [==============================] - 22s 29ms/step - loss: 2.6727 - accuracy: 0.4009\n",
      "Epoch 46/100\n",
      "782/782 [==============================] - 23s 29ms/step - loss: 2.6520 - accuracy: 0.4038\n",
      "Epoch 47/100\n",
      "782/782 [==============================] - 23s 29ms/step - loss: 2.6262 - accuracy: 0.4080\n",
      "Epoch 48/100\n",
      "782/782 [==============================] - 23s 29ms/step - loss: 2.6081 - accuracy: 0.4108\n",
      "Epoch 49/100\n",
      "782/782 [==============================] - 23s 29ms/step - loss: 2.5855 - accuracy: 0.4159\n",
      "Epoch 50/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 2.5622 - accuracy: 0.4182\n",
      "Epoch 51/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 2.5418 - accuracy: 0.4217\n",
      "Epoch 52/100\n",
      "782/782 [==============================] - 23s 29ms/step - loss: 2.5167 - accuracy: 0.4249\n",
      "Epoch 53/100\n",
      "782/782 [==============================] - 22s 29ms/step - loss: 2.4991 - accuracy: 0.4284\n",
      "Epoch 54/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 2.4851 - accuracy: 0.4305\n",
      "Epoch 55/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 2.4590 - accuracy: 0.4361\n",
      "Epoch 56/100\n",
      "782/782 [==============================] - 22s 29ms/step - loss: 2.4431 - accuracy: 0.4388\n",
      "Epoch 57/100\n",
      "782/782 [==============================] - 23s 29ms/step - loss: 2.4240 - accuracy: 0.4414\n",
      "Epoch 58/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 2.4087 - accuracy: 0.4443\n",
      "Epoch 59/100\n",
      "782/782 [==============================] - 22s 29ms/step - loss: 2.3934 - accuracy: 0.4463\n",
      "Epoch 60/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 2.3738 - accuracy: 0.4491\n",
      "Epoch 61/100\n",
      "782/782 [==============================] - 22s 29ms/step - loss: 2.3614 - accuracy: 0.4527\n",
      "Epoch 62/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 2.3428 - accuracy: 0.4547\n",
      "Epoch 63/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 2.3271 - accuracy: 0.4582\n",
      "Epoch 64/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 2.3116 - accuracy: 0.4600\n",
      "Epoch 65/100\n",
      "782/782 [==============================] - 22s 29ms/step - loss: 2.2984 - accuracy: 0.4634\n",
      "Epoch 66/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 2.2874 - accuracy: 0.4647\n",
      "Epoch 67/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 2.2702 - accuracy: 0.4687\n",
      "Epoch 68/100\n",
      "782/782 [==============================] - 23s 29ms/step - loss: 2.2543 - accuracy: 0.4716\n",
      "Epoch 69/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 2.2405 - accuracy: 0.4728\n",
      "Epoch 70/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 2.2329 - accuracy: 0.4739\n",
      "Epoch 71/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 2.2167 - accuracy: 0.4773\n",
      "Epoch 72/100\n",
      "782/782 [==============================] - 21s 27ms/step - loss: 2.2043 - accuracy: 0.4798\n",
      "Epoch 73/100\n",
      "782/782 [==============================] - 21s 27ms/step - loss: 2.1897 - accuracy: 0.4818\n",
      "Epoch 74/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 2.1823 - accuracy: 0.4841\n",
      "Epoch 75/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 2.1707 - accuracy: 0.4843\n",
      "Epoch 76/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 2.1533 - accuracy: 0.4883\n",
      "Epoch 77/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 2.1443 - accuracy: 0.4898\n",
      "Epoch 78/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 2.1359 - accuracy: 0.4916\n",
      "Epoch 79/100\n",
      "782/782 [==============================] - 22s 29ms/step - loss: 2.1203 - accuracy: 0.4938\n",
      "Epoch 80/100\n",
      "782/782 [==============================] - 22s 29ms/step - loss: 2.1141 - accuracy: 0.4945\n",
      "Epoch 81/100\n",
      "782/782 [==============================] - 22s 29ms/step - loss: 2.1083 - accuracy: 0.4961\n",
      "Epoch 82/100\n",
      "782/782 [==============================] - 22s 29ms/step - loss: 2.0907 - accuracy: 0.4990\n",
      "Epoch 83/100\n",
      "782/782 [==============================] - 22s 29ms/step - loss: 2.0801 - accuracy: 0.5022\n",
      "Epoch 84/100\n",
      "782/782 [==============================] - 22s 29ms/step - loss: 2.0738 - accuracy: 0.5020\n",
      "Epoch 85/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 2.0650 - accuracy: 0.5032\n",
      "Epoch 86/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 2.0529 - accuracy: 0.5057\n",
      "Epoch 87/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 2.0439 - accuracy: 0.5074\n",
      "Epoch 88/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 2.0387 - accuracy: 0.5082\n",
      "Epoch 89/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 2.0243 - accuracy: 0.5117\n",
      "Epoch 90/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 2.0167 - accuracy: 0.5135\n",
      "Epoch 91/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 2.0094 - accuracy: 0.5152\n",
      "Epoch 92/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 2.0057 - accuracy: 0.5156\n",
      "Epoch 93/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 1.9967 - accuracy: 0.5166\n",
      "Epoch 94/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 1.9846 - accuracy: 0.5191\n",
      "Epoch 95/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 1.9762 - accuracy: 0.5202\n",
      "Epoch 96/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 1.9607 - accuracy: 0.5242\n",
      "Epoch 97/100\n",
      "782/782 [==============================] - 22s 29ms/step - loss: 1.9582 - accuracy: 0.5232\n",
      "Epoch 98/100\n",
      "782/782 [==============================] - 22s 29ms/step - loss: 1.9522 - accuracy: 0.5241\n",
      "Epoch 99/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 1.9500 - accuracy: 0.5256\n",
      "Epoch 100/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 1.9478 - accuracy: 0.5251\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e448bf6bb0>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile the model\n",
    "model_2.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "# Train the model\n",
    "model_2.fit(x,y, batch_size=256,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-113-397974375f63>:8: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'preposterously be stained to leave for nothing so unkind to'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text_seq(model_2, tokenizer, seq_length, seed_text, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Text Generation with TensorFlow, Keras and LSTM.ipynb",
   "provenance": [
    {
     "file_id": "1gO9e0i5i1k6hQu_-OzN0D71WGZSLCEad",
     "timestamp": 1614397422164
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
