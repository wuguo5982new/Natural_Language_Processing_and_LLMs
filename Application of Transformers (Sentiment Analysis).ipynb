{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8bf3f4e5",
   "metadata": {},
   "source": [
    "### Application of Transformers (for Sentiment Analysis)\n",
    "1. Pipeline('text-classfication');\n",
    "2. Fine-Tuning hypermeters of model; \n",
    "3. Using Cuda instead of cpu for speedy training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "105c520e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from pprint import pprint\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import TrainingArguments\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from torchinfo import summary\n",
    "from transformers import Trainer\n",
    "from datasets import load_metric\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c586a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Pytorch CUDA Version is  11.7\n"
     ]
    }
   ],
   "source": [
    "# pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda:0\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "device = torch.device(device)\n",
    "print(device)\n",
    "print(\"Pytorch CUDA Version is \", torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9a9b689",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset glue (C:/Users/Sealion/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed76e6429d9b45d6a2b98832b06b7268",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# !pip install transformers datasets\n",
    "raw_datasets = load_dataset('glue', 'sst2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9227c4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence', 'label', 'idx'],\n",
       "        num_rows: 67349\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence', 'label', 'idx'],\n",
       "        num_rows: 872\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence', 'label', 'idx'],\n",
       "        num_rows: 1821\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a83a1a6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['sentence', 'label', 'idx'],\n",
       "    num_rows: 67349\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da3e7f1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_TF_DATASET_REFS',\n",
       " '__class__',\n",
       " '__del__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__enter__',\n",
       " '__eq__',\n",
       " '__exit__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__getitems__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_build_local_temp_path',\n",
       " '_check_index_is_initialized',\n",
       " '_data',\n",
       " '_estimate_nbytes',\n",
       " '_fingerprint',\n",
       " '_format_columns',\n",
       " '_format_kwargs',\n",
       " '_format_type',\n",
       " '_generate_tables_from_cache_file',\n",
       " '_generate_tables_from_shards',\n",
       " '_get_cache_file_path',\n",
       " '_get_output_signature',\n",
       " '_getitem',\n",
       " '_indexes',\n",
       " '_indices',\n",
       " '_info',\n",
       " '_map_single',\n",
       " '_new_dataset_with_indices',\n",
       " '_output_all_columns',\n",
       " '_push_parquet_shards_to_hub',\n",
       " '_save_to_disk_single',\n",
       " '_select_contiguous',\n",
       " '_select_with_indices_mapping',\n",
       " '_split',\n",
       " 'add_column',\n",
       " 'add_elasticsearch_index',\n",
       " 'add_faiss_index',\n",
       " 'add_faiss_index_from_external_arrays',\n",
       " 'add_item',\n",
       " 'align_labels_with_mapping',\n",
       " 'builder_name',\n",
       " 'cache_files',\n",
       " 'cast',\n",
       " 'cast_column',\n",
       " 'citation',\n",
       " 'class_encode_column',\n",
       " 'cleanup_cache_files',\n",
       " 'column_names',\n",
       " 'config_name',\n",
       " 'data',\n",
       " 'dataset_size',\n",
       " 'description',\n",
       " 'download_checksums',\n",
       " 'download_size',\n",
       " 'drop_index',\n",
       " 'export',\n",
       " 'features',\n",
       " 'filter',\n",
       " 'flatten',\n",
       " 'flatten_indices',\n",
       " 'format',\n",
       " 'formatted_as',\n",
       " 'from_buffer',\n",
       " 'from_csv',\n",
       " 'from_dict',\n",
       " 'from_file',\n",
       " 'from_generator',\n",
       " 'from_json',\n",
       " 'from_list',\n",
       " 'from_pandas',\n",
       " 'from_parquet',\n",
       " 'from_spark',\n",
       " 'from_sql',\n",
       " 'from_text',\n",
       " 'get_index',\n",
       " 'get_nearest_examples',\n",
       " 'get_nearest_examples_batch',\n",
       " 'homepage',\n",
       " 'info',\n",
       " 'is_index_initialized',\n",
       " 'iter',\n",
       " 'license',\n",
       " 'list_indexes',\n",
       " 'load_elasticsearch_index',\n",
       " 'load_faiss_index',\n",
       " 'load_from_disk',\n",
       " 'map',\n",
       " 'num_columns',\n",
       " 'num_rows',\n",
       " 'prepare_for_task',\n",
       " 'push_to_hub',\n",
       " 'remove_columns',\n",
       " 'rename_column',\n",
       " 'rename_columns',\n",
       " 'reset_format',\n",
       " 'save_faiss_index',\n",
       " 'save_to_disk',\n",
       " 'search',\n",
       " 'search_batch',\n",
       " 'select',\n",
       " 'select_columns',\n",
       " 'set_format',\n",
       " 'set_transform',\n",
       " 'shape',\n",
       " 'shard',\n",
       " 'shuffle',\n",
       " 'size_in_bytes',\n",
       " 'sort',\n",
       " 'split',\n",
       " 'supervised_keys',\n",
       " 'task_templates',\n",
       " 'to_csv',\n",
       " 'to_dict',\n",
       " 'to_iterable_dataset',\n",
       " 'to_json',\n",
       " 'to_list',\n",
       " 'to_pandas',\n",
       " 'to_parquet',\n",
       " 'to_sql',\n",
       " 'to_tf_dataset',\n",
       " 'train_test_split',\n",
       " 'unique',\n",
       " 'version',\n",
       " 'with_format',\n",
       " 'with_transform']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(raw_datasets['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "557d671b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datasets.arrow_dataset.Dataset"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(raw_datasets['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e51d82c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MemoryMappedTable\n",
       "sentence: string\n",
       "label: int64\n",
       "idx: int32\n",
       "----\n",
       "sentence: [[\"hide new secretions from the parental units \",\"contains no wit , only labored gags \",\"that loves its characters and communicates something rather beautiful about human nature \",\"remains utterly satisfied to remain the same throughout \",\"on the worst revenge-of-the-nerds clichÃ©s the filmmakers could dredge up \",...,\"you wish you were at home watching that movie instead of in the theater watching this one \",\"'s no point in extracting the bare bones of byatt 's plot for purposes of bland hollywood romance \",\"underdeveloped \",\"the jokes are flat \",\"a heartening tale of small victories \"],[\"suspense , intriguing characters and bizarre bank robberies , \",\"a gritty police thriller with all the dysfunctional family dynamics one could wish for \",\"with a wonderful ensemble cast of characters that bring the routine day to day struggles of the working class to life \",\"nonetheless appreciates the art and reveals a music scene that transcends culture and race . \",\"do we really need the tiger beat version ? \",...,\"when there 's nothing else happening \",\"on cable \",\"it with ring , \",\"far from a groundbreaking endeavor \",\"that these women are spectacular \"],...,[\"it does turn out to be a bit of a cheat in the end \",\"may be convinced that he has something significant to say \",\"to be both hugely entertaining and uplifting . \",\", boredom never takes hold . \",\"left to work with , sort of like michael jackson 's nose \",...,\"from a severe case of hollywood-itis \",\"the very best of them \",\"thrills , \",\"'s attracting audiences to unfaithful \",\"impressively delicate range \"],[\"starts off promisingly but then proceeds to flop \",\"distinguished actor \",\"on their parents ' anguish \",\"pays off and is effective if you stick with it \",\"is n't particularly funny \",...,\"a delightful comedy \",\"anguish , anger and frustration \",\"at achieving the modest , crowd-pleasing goals it sets for itself \",\"a patient viewer \",\"this new jangle of noise , mayhem and stupidity must be a serious contender for the title . \"]]\n",
       "label: [[0,0,1,0,0,...,0,0,0,0,1],[1,1,1,1,0,...,0,0,1,0,1],...,[0,0,1,1,0,...,0,1,1,1,1],[0,1,0,1,0,...,1,0,1,1,0]]\n",
       "idx: [[0,1,2,3,4,...,995,996,997,998,999],[1000,1001,1002,1003,1004,...,1995,1996,1997,1998,1999],...,[66000,66001,66002,66003,66004,...,66995,66996,66997,66998,66999],[67000,67001,67002,67003,67004,...,67344,67345,67346,67347,67348]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets['train'].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5ddf5c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyarrow.lib.ChunkedArray object at 0x000002320DF2A040>\n",
       "[\n",
       "  [\n",
       "    \"hide new secretions from the parental units \",\n",
       "    \"contains no wit , only labored gags \",\n",
       "    \"that loves its characters and communicates something rather beautiful about human nature \",\n",
       "    \"remains utterly satisfied to remain the same throughout \",\n",
       "    \"on the worst revenge-of-the-nerds clichÃ©s the filmmakers could dredge up \",\n",
       "    ...\n",
       "    \"you wish you were at home watching that movie instead of in the theater watching this one \",\n",
       "    \"'s no point in extracting the bare bones of byatt 's plot for purposes of bland hollywood romance \",\n",
       "    \"underdeveloped \",\n",
       "    \"the jokes are flat \",\n",
       "    \"a heartening tale of small victories \"\n",
       "  ],\n",
       "  [\n",
       "    \"suspense , intriguing characters and bizarre bank robberies , \",\n",
       "    \"a gritty police thriller with all the dysfunctional family dynamics one could wish for \",\n",
       "    \"with a wonderful ensemble cast of characters that bring the routine day to day struggles of the working class to life \",\n",
       "    \"nonetheless appreciates the art and reveals a music scene that transcends culture and race . \",\n",
       "    \"do we really need the tiger beat version ? \",\n",
       "    ...\n",
       "    \"when there 's nothing else happening \",\n",
       "    \"on cable \",\n",
       "    \"it with ring , \",\n",
       "    \"far from a groundbreaking endeavor \",\n",
       "    \"that these women are spectacular \"\n",
       "  ],\n",
       "...,\n",
       "  [\n",
       "    \"it does turn out to be a bit of a cheat in the end \",\n",
       "    \"may be convinced that he has something significant to say \",\n",
       "    \"to be both hugely entertaining and uplifting . \",\n",
       "    \", boredom never takes hold . \",\n",
       "    \"left to work with , sort of like michael jackson 's nose \",\n",
       "    ...\n",
       "    \"from a severe case of hollywood-itis \",\n",
       "    \"the very best of them \",\n",
       "    \"thrills , \",\n",
       "    \"'s attracting audiences to unfaithful \",\n",
       "    \"impressively delicate range \"\n",
       "  ],\n",
       "  [\n",
       "    \"starts off promisingly but then proceeds to flop \",\n",
       "    \"distinguished actor \",\n",
       "    \"on their parents ' anguish \",\n",
       "    \"pays off and is effective if you stick with it \",\n",
       "    \"is n't particularly funny \",\n",
       "    ...\n",
       "    \"a delightful comedy \",\n",
       "    \"anguish , anger and frustration \",\n",
       "    \"at achieving the modest , crowd-pleasing goals it sets for itself \",\n",
       "    \"a patient viewer \",\n",
       "    \"this new jangle of noise , mayhem and stupidity must be a serious contender for the title . \"\n",
       "  ]\n",
       "]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets['train'].data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1243f0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': ['suspense , intriguing characters and bizarre bank robberies , ',\n",
       "  'a gritty police thriller with all the dysfunctional family dynamics one could wish for ',\n",
       "  'with a wonderful ensemble cast of characters that bring the routine day to day struggles of the working class to life '],\n",
       " 'label': [1, 1, 1],\n",
       " 'idx': [1000, 1001, 1002]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets['train'][1000:1003]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5160d86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': Value(dtype='string', id=None),\n",
       " 'label': ClassLabel(names=['negative', 'positive'], id=None),\n",
       " 'idx': Value(dtype='int32', id=None)}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets['train'].features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5c16f1",
   "metadata": {},
   "source": [
    "#### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4580e6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using pretrained model ('distilbert-base-uncased')\n",
    "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dcc0616c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hide new secretions from the parental units ',\n",
       " 'contains no wit , only labored gags ',\n",
       " 'that loves its characters and communicates something rather beautiful about human nature ']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## test samples\n",
    "raw_datasets['train'][0:3]['sentence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6ebf95f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [[101, 5342, 2047, 3595, 8496, 2013, 1996, 18643, 3197, 102], [101, 3397, 2053, 15966, 1010, 2069, 4450, 2098, 18201, 2015, 102], [101, 2008, 7459, 2049, 3494, 1998, 10639, 2015, 2242, 2738, 3376, 2055, 2529, 3267, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"
     ]
    }
   ],
   "source": [
    "tokenized_sentences = tokenizer(raw_datasets['train'][0:3]['sentence'])\n",
    "print(tokenized_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa191e17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/67349 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1821 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence', 'label', 'idx', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 67349\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence', 'label', 'idx', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 872\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence', 'label', 'idx', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 1821\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Function\n",
    "def tokenize_fn(batch):\n",
    "    return tokenizer(batch['sentence'], truncation=True)\n",
    "tokenized_datasets = raw_datasets.map(tokenize_fn, batched=True)\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9981f6b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.scriptrun = azureml.core.script_run:ScriptRun._from_run_dto with exception (pywin32 228 (c:\\users\\sealion\\anaconda3\\lib\\site-packages), Requirement.parse('pywin32==227; sys_platform == \"win32\"'), {'docker'}).\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments('my_trainer', evaluation_strategy='epoch', save_strategy='epoch', num_train_epochs=1,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f576dfa",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "101f9edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_projector.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "transformers.models.distilbert.modeling_distilbert.DistilBertForSequenceClassification"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)\n",
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e4d86e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4b23b4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "================================================================================\n",
       "Layer (type:depth-idx)                                  Param #\n",
       "================================================================================\n",
       "DistilBertForSequenceClassification                     --\n",
       "ââDistilBertModel: 1-1                                  --\n",
       "â    ââEmbeddings: 2-1                                  --\n",
       "â    â    ââEmbedding: 3-1                              23,440,896\n",
       "â    â    ââEmbedding: 3-2                              393,216\n",
       "â    â    ââLayerNorm: 3-3                              1,536\n",
       "â    â    ââDropout: 3-4                                --\n",
       "â    ââTransformer: 2-2                                 --\n",
       "â    â    ââModuleList: 3-5                             42,527,232\n",
       "ââLinear: 1-2                                           590,592\n",
       "ââLinear: 1-3                                           1,538\n",
       "ââDropout: 1-4                                          --\n",
       "================================================================================\n",
       "Total params: 66,955,010\n",
       "Trainable params: 66,955,010\n",
       "Non-trainable params: 0\n",
       "================================================================================"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install torchinfo\n",
    "# summary(model, input_size=(16,512), dtypes=['torch.IntTensor'], device=\"cpu\")   ## cudo:0\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2ff9e220",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fine-tuning parameters before training\n",
    "params_before = []\n",
    "for name, p in model.named_parameters():\n",
    "    params_before.append(p.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "54f02ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = load_metric('glue', 'sst2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5511ed4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.6666666666666666}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "metric.compute(predictions=[1,0,1], references=[1,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eb197712",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(logits_and_labels):\n",
    "    logits, labels = logits_and_labels\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9c507d",
   "metadata": {},
   "source": [
    "#### Training (long time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dfb0cc46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: idx, sentence. If idx, sentence are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "C:\\Users\\Sealion\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 67349\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8419\n",
      "  Number of trainable parameters = 66955010\n",
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8419' max='8419' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8419/8419 07:32, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.195000</td>\n",
       "      <td>0.382774</td>\n",
       "      <td>0.896789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: idx, sentence. If idx, sentence are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 872\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to my_trainer\\checkpoint-8419\n",
      "Configuration saved in my_trainer\\checkpoint-8419\\config.json\n",
      "Model weights saved in my_trainer\\checkpoint-8419\\pytorch_model.bin\n",
      "tokenizer config file saved in my_trainer\\checkpoint-8419\\tokenizer_config.json\n",
      "Special tokens file saved in my_trainer\\checkpoint-8419\\special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=8419, training_loss=0.26894088311948094, metrics={'train_runtime': 454.2661, 'train_samples_per_second': 148.259, 'train_steps_per_second': 18.533, 'total_flos': 518400815624736.0, 'train_loss': 0.26894088311948094, 'epoch': 1.0})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(model, training_args, train_dataset=tokenized_datasets['train'], eval_dataset=tokenized_datasets['validation'],\n",
    "                 tokenizer=tokenizer, compute_metrics=compute_metrics,)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a624ccf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to my_saved_model\n",
      "Configuration saved in my_saved_model\\config.json\n",
      "Model weights saved in my_saved_model\\pytorch_model.bin\n",
      "tokenizer config file saved in my_saved_model\\tokenizer_config.json\n",
      "Special tokens file saved in my_saved_model\\special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model('my_saved_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "65697325",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file my_saved_model\\config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"my_saved_model\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file my_saved_model\\config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"my_saved_model\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file my_saved_model\\pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at my_saved_model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading file vocab.txt\n",
      "loading file tokenizer.json\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline   ## pipeline for model or tokenized raw data\n",
    "newmodel = pipeline('text-classification', model='my_saved_model', device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3932423b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_1', 'score': 0.9996652603149414}]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newmodel('This method works great')   # positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0b1f8e16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_0', 'score': 0.9978487491607666}]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newmodel('This method works bad')     # negative "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b7027838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13485.047\n",
      "91.91156\n",
      "1.7997546\n",
      "1.1370147\n",
      "1305.2952\n",
      "1.6901932\n",
      "1294.8547\n",
      "0.0026736008\n",
      "1189.7288\n",
      "1.0605416\n",
      "1128.602\n",
      "0.84680164\n",
      "1.7160456\n",
      "0.85775936\n",
      "4919.0845\n",
      "5.7258983\n",
      "4515.952\n",
      "0.69795597\n",
      "1.6095532\n",
      "0.67171335\n",
      "1297.0327\n",
      "1.6288805\n",
      "1276.0375\n",
      "0.002484723\n",
      "1091.8843\n",
      "0.8281398\n",
      "1042.3605\n",
      "0.73171365\n",
      "1.533285\n",
      "0.7256043\n",
      "4867.947\n",
      "5.3627076\n",
      "4407.6807\n",
      "0.692232\n",
      "1.4428861\n",
      "0.6802748\n",
      "1273.0339\n",
      "1.5718892\n",
      "1277.5612\n",
      "0.0022093891\n",
      "1103.8116\n",
      "0.7235434\n",
      "1093.535\n",
      "0.7237096\n",
      "1.5213573\n",
      "0.7750572\n",
      "4882.576\n",
      "5.5375686\n",
      "4294.3545\n",
      "0.6945188\n",
      "1.4406718\n",
      "0.6699518\n",
      "1275.6019\n",
      "1.3967298\n",
      "1287.1619\n",
      "0.0028095916\n",
      "1131.5803\n",
      "0.70965075\n",
      "1088.8489\n",
      "0.68552005\n",
      "1.459613\n",
      "0.70057225\n",
      "4798.997\n",
      "5.4915953\n",
      "4087.5652\n",
      "0.6691375\n",
      "1.3874807\n",
      "0.6912411\n",
      "1206.1769\n",
      "1.4691503\n",
      "1212.032\n",
      "0.0016011212\n",
      "990.1749\n",
      "0.71090114\n",
      "1004.90375\n",
      "0.8583193\n",
      "1.3801863\n",
      "0.8401797\n",
      "4566.8\n",
      "5.2452526\n",
      "3504.8257\n",
      "0.76673514\n",
      "1.2926623\n",
      "0.7090116\n",
      "1161.9203\n",
      "1.4425095\n",
      "1135.8972\n",
      "0.0009350345\n",
      "936.16693\n",
      "0.70254314\n",
      "942.5768\n",
      "0.85767925\n",
      "1.3357252\n",
      "1.1096609\n",
      "3655.7778\n",
      "4.494397\n",
      "3223.699\n",
      "0.96542\n",
      "1.3582172\n",
      "0.7209202\n",
      "917.5637\n",
      "0.9749305\n",
      "2.2860732\n",
      "0.00045893024\n"
     ]
    }
   ],
   "source": [
    "## Extract Fine-tuning parameters after training, and compare them.\n",
    "params_after = []\n",
    "for name, p in model.named_parameters():\n",
    "    params_after.append(p.detach().cpu().numpy())\n",
    "    \n",
    "for p1, p2 in zip(params_before, params_after):\n",
    "    print(np.sum(np.abs(p1-p2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cef291a",
   "metadata": {},
   "source": [
    "#### Acknowledge:\n",
    "\n",
    "1. Dataset: https://huggingface.co/datasets\n",
    "2. Courses of Lazy Programmer\n",
    "\n",
    "All above is for practice purposes only."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7850fcf3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835c77e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
